```markdown
# Проекты по классификации изображений

В этом репозитории собраны скрипты для подготовки данных, поиска оптимальных гиперпараметров, обучения и оценки моделей для задачи классификации изображений с тремя классами: `real`, `fake`, `notdoc`.

Все предобученные модели (чекпоинты) нужно разместить в архив `top_models.zip` в корне репозитория перед запуском соответствующих скриптов.

## Структура репозитория

```

├── data/                       # Корневая папка с данными │   ├── train/                  # Тренировочные изображения по классам │   │   ├── real/ │   │   ├── fake/ │   │   └── notdoc/ │   └── val/                    # Папка для валидационных изображений (будет заполнена скриптом) ├── models/                     # Распакованный архив top\_models.zip (чекпоинты моделей) ├── saved\_models/               # Папка для автоматического сохранения моделей при оптимизации ├── split\_data.py               # Скрипт для разбиения train → val (20% изображений) ├── tune\_optuna.py              # Базовый скрипт Optuna для поиска гиперпараметров ├── evaluate.py                 # Скрипт для загрузки лучшей модели и оценки на валидации ├── tune\_optuna\_extended.py     # Расширенный Optuna c автосохранением промежуточных чекпоинтов ├── ensemble.py                 # Скрипт для построения ансамбля из топ‑k моделей и сравнения F1 └── top\_models.zip              # Архив с предварительно обученными моделями

````

## Установка окружения

1. Склонируйте репозиторий:
   ```bash
   git clone <URL вашего репозитория>
   cd <имя репозитория>
````

2. Создайте виртуальное окружение и установите зависимости:

   ```bash
   python -m venv venv
   source venv/bin/activate       # Linux/Mac
   venv\\Scripts\\activate      # Windows
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

> **Примечание:** Если файла `requirements.txt` нет, установите вручную:
>
> ```bash
> pip install torch torchvision optuna scikit-learn pillow
> ```

## Подготовка данных

1. Разместите исходные данные:

   * `data/train/real/`, `data/train/fake/`, `data/train/notdoc/` — ваши изображения.

2. Запустите скрипт для разбиения валидации:

   ```bash
   python split_data.py
   ```

   > Скопирует 20% случайных изображений из каждой папки `train/<class>` → `val/<class>`.

## Поиск гиперпараметров с Optuna

### Базовая версия

```bash
python tune_optuna.py
```

* Настраивает параметры:

  * Размер изображения: `224` или `256`
  * Архитектура: `resnet18`, `resnet50`, `efficientnet_b0`
  * Оптимизатор: `Adam`, `AdamW`, `SGD`
  * И др.
* Сохраняет лучший результат в консоли.

### Расширенная версия с автосохранением

```bash
python tune_optuna_extended.py
```

* Дополнительно:

  * Использует AMP (Optionally)
  * Различные виды scheduler'ов
  * Сохраняет чекпоинт лучшей модели в `saved_models/` после каждой эпохи

## Оценка одной модели

Укажите путь к файлу чекпоинта в `evaluate.py` (переменная `MODEL_PATH`).

```bash
python evaluate.py
```

* Выведет:

  * Macro F1-score
  * Classification Report (precision, recall, f1)
  * Confusion Matrix

## Ансамблирование моделей

1. Распакуйте `top_models.zip` в папку `models/`.
2. Запустите:

   ```bash
   python ensemble.py
   ```
3. Скрипт автоматически выберет топ‑20 моделей по метрике F1, рассчитает ансамбли из 1 до 20 и выведет сравнение.

## Настройка путей

Во всех скриптах путь к папке с данными настроен через константу `BASE_DIR` или `VAL_DIR`. При необходимости измените эти переменные на ваши локальные пути.

## Контакты

По вопросам и предложениям обращайтесь к автору проекта.

```
```
