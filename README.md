# Проекты по классификации изображений

В этом репозитории собраны скрипты для подготовки данных, обучения и оценки моделей для задачи классификации изображений с тремя классами: `real`, `fake`, `notdoc`.

> **Доступ к данным и моделям:**
> По этой ссылке уже доступны:
>
> * разделённый на тренировочную и валидационную выборки датасет в папке `data` (`train` и `val`),
> * папка `top_models` с топ‑20 предобученных моделей для скриптов `Quality.py` и `ans_fin.py`  
>   [https://drive.google.com/drive/folders/1MrNzTy0yIfjwOMoL9r6lHOaGKsaxhSzw?usp=sharing](https://drive.google.com/drive/folders/1MrNzTy0yIfjwOMoL9r6lHOaGKsaxhSzw?usp=sharing)

Все модели (чекпоинты) находятся по ссылке в архиве `top_models.zip`. Скрипты `Quality.py` и `ans_fin.py` сразу используют эти готовые модели — запуск `ans.py` для обучения повторно **не требуется**.

---

## Структура репозитория

```
├── data/                       # Корневая папка с данными
│   ├── train/                  # Тренировочные изображения по классам
│   │   ├── real/
│   │   ├── fake/
│   │   └── notdoc/
│   └── val/                    # Валидационные изображения по классам
├── top_models/                 # Распакованный архив top_models.zip (чекпоинты моделей)
├── saved_models/               # Папка для сохранения моделей при обучении
├── split_data.py               # Скрипт для разбиения train → val (20% изображений)
├── train.py                    # Базовый скрипт обучения и подбора гиперпараметров с Optuna
├── ans.py                      # Расширенный скрипт с автосохранением моделей
├── Quality.py                  # Скрипт для оценки одной модели на валидации
├── ans_fin.py                  # Скрипт для ансамблирования топ‑моделей и сравнения F1
└── top_models.zip              # Архив с предобученными моделями
```

---

## Установка окружения

1. Склонируйте репозиторий:

```bash
git clone https://github.com/I-am-a-cup/dl-authenticity-detector
cd dl-authenticity-detector
```

2. Создайте виртуальное окружение и установите зависимости вручную:

```bash
python -m venv venv
source venv/bin/activate       # Для Linux/Mac
venv\Scripts\activate          # Для Windows

pip install --upgrade pip
pip install torch torchvision optuna scikit-learn pillow
```

---

## Подготовка данных

> **Важно:** Если вы используете уже разделённый датасет из папки `data`, то запуск `split_data.py` **не обязателен**.

1. Убедитесь, что структура папок соответствует следующей:

```
data/
├── train/
│   ├── real/
│   ├── fake/
│   └── notdoc/
└── val/
    ├── real/
    ├── fake/
    └── notdoc/
```

2. (Опционально) для повторного разбиения датасета запустите:

```bash
python split_data.py
```

---

## Поиск гиперпараметров и обучение

### Базовая версия обучения

```bash
python train.py
```

* Использует Optuna для подбора:
  * Размер изображения: 224 или 256
  * Архитектура модели: `resnet18`, `resnet50`, `efficientnet_b0`
  * Оптимизатор: `Adam`, `AdamW`, `SGD`
* Лучшие параметры и результат выводятся в консоль.

### Расширенная версия с автосохранением моделей

```bash
python ans.py
```

* Дополнительно:
  * Используется AMP (опционально)
  * Поддержка различных scheduler'ов
  * Сохраняет лучший чекпоинт после каждой эпохи в `saved_models/`

---

## Оценка одной модели

1. Укажите путь к файлу модели в переменной `MODEL_PATH` внутри `Quality.py`.

2. Запустите:

```bash
python Quality.py
```

* Выведет:
  * Macro F1-score
  * Classification Report
  * Confusion Matrix

---

## Ансамблирование моделей

1. Распакуйте `top_models.zip` в папку `top_models/`.

2. Запустите:

```bash
python ans_fin.py
```

* Скрипт:
  * Автоматически выберет топ‑20 моделей по F1
  * Построит ансамбли из 1–20 моделей
  * Выведет сравнение по метрике

---

## Настройка путей

Во всех скриптах пути к данным заданы через константы `BASE_DIR` и `VAL_DIR`. При необходимости — измените их вручную на актуальные.
